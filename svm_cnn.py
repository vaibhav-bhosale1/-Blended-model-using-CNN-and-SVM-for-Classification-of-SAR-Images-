# -*- coding: utf-8 -*-
"""svm_cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1avZkZBp5vdCl4Ftn4o6v-7IVKqCu6oCY
"""

!python --version

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import os.path
from sklearn.model_selection import train_test_split
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report


params = {"ytick.color" : "w",
          "xtick.color" : "w",
          "axes.labelcolor" : "w",
          "axes.edgecolor" : "w",
          "figure.figsize" : (10,10),
          "axes.titlecolor" : 'w',
          "axes.facecolor" : 'w',
          "figure.facecolor" : 'k'}

colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

# %matplotlib inline
print(tf.__version__)

image_dir = Path(r"D:\ENTC\TY\Sem 5\PR\MODEL3\MODEL DATASET-20241022T053927Z-001\MODEL DATASET")
image_dir

filepaths = list(image_dir.rglob('*.*'))  # Get all files recursively

# Filter files by image extensions (you can add more extensions as needed)
valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.tif'}

# Select only files with valid image extensions
filepaths = [filepath for filepath in filepaths if filepath.suffix.lower() in valid_extensions]

# Extract labels by getting the parent directory name (i.e., label1, label2, etc.)
labels = list(map(lambda x: x.parent.name, filepaths))

# Create a pandas DataFrame with filepaths and corresponding labels
filepaths = pd.Series(filepaths, name='Filepath').astype(str)  # Convert Path objects to string
labels = pd.Series(labels, name='Label')

# Combine filepaths and labels into a single DataFrame
images = pd.concat([filepaths, labels], axis=1)

# Check the first few rows of the dataframe to verify everything is correct
print(images.head())

# Check the total number of images to ensure all are included
print(f"Total images found: {len(images)}")

images.Label.value_counts()

train_df, test_df = train_test_split(images, train_size=0.8, shuffle=True, random_state=1)

train_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    validation_split=0.2
)

test_generator = tf.keras.preprocessing.image.ImageDataGenerator(
)

train_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(128, 128),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(128, 128),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(128, 128),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)
print(test_images)

image_size = (128,128)
batch_size = 32

num_classes=7

metrics = [
      keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),
      keras.metrics.AUC(name='auc'),
      keras.metrics.AUC(name='prc', curve='PR'),
]

model2 = tf.keras.Sequential([
  #tf.keras.layers.InputLayer(input_shape=(image_size + (1,))),
  tf.keras.layers.InputLayer(shape=(128,128,1)),
  tf.keras.layers.Rescaling(1./255),
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(num_classes, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation
             ='softmax')
])
model2.summary()

# model2.compile(
#   optimizer='adam',
#   loss='categorical_crossentropy',
#   metrics=metrics)
model2.compile(optimizer = 'adam', loss = 'squared_hinge', metrics = ['accuracy'])

history2 = model2.fit(train_images, epochs=10, validation_data=val_images)

results = model2.evaluate(test_images, verbose=0)
print(results)
print(f"Test Accuracy: {np.round(results[1] * 100,2)}%")

predictions = np.argmax(model2.predict(test_images), axis=1)

matrix = confusion_matrix(test_images.labels, predictions)
report= classification_report(test_images.labels, predictions, target_names=test_images.class_indices, zero_division=0)

with plt.rc_context(params):
    fig = plt.figure(figsize = (10,10))
    ax1 = fig.add_subplot(1,1,1)
    sns.set(font_scale=1.4) #for label size
    sns.heatmap(matrix,cmap='binary', annot=True, fmt='d', xticklabels=test_images.class_indices, yticklabels=test_images.class_indices, annot_kws={"size": 10},cbar = False);
    ax1.set_ylabel('True Values',fontsize=14)
    ax1.set_xlabel('Predicted Values',fontsize=14)
    plt.show()

print("Classification Report:\n", report)

import pandas as pd
data_his = pd.DataFrame(history2.history)
data_his

plt.style.use('ggplot')
fig = plt.figure(figsize=(18, 4))
plt.plot(data_his['loss'], label = 'train')
plt.plot(data_his['val_loss'], label = 'val')
plt.legend()
plt.title('Loss Function')
plt.show()
fig.savefig("Loss Function",dpi=700)

fig = plt.figure(figsize=(18, 4))
plt.plot(data_his['accuracy'], label = 'train')
plt.plot(data_his['val_accuracy'], label = 'val')
plt.legend()
plt.title('Accuracy Function')
plt.show()
fig.savefig("Accuracy Function",dpi=700)

model2.save(r"C:\Users\Rajat Dhanure\Downloads\cnn_svm.keras")

from tensorflow.keras.models import load_model
model_path = r"C:\Users\Rajat Dhanure\Downloads\cnn_svm.keras"
model = load_model(model_path)

class_names = ['2s1', 'brdm2',  'btr60', 'd7','t62', 'zil 161','zsu234']
manual_indices = [0,1,2,3,4,5,6]  # Custom sequence for class indices

# Create the DataFrame with manual sequence
df = pd.DataFrame({'names': class_names, 'index': manual_indices})

# Check the DataFrame
print(df)

import tkinter as tk
from tkinter import filedialog

root = tk.Tk()
root.withdraw()

file_path = filedialog.askopenfilename(
    title="Select Image",
    filetypes=[ ("All files", "*.*")]
)

if file_path:
    image = keras.utils.load_img(
        path=file_path,
        color_mode='grayscale',
        target_size=(128, 128)
    )

    image_array = keras.utils.img_to_array(image)
    image_array = tf.expand_dims(image_array, 0)

else:
    print("No file selected.")

image

def predict_t72(model):
    predictions = model.predict(image_array)
    predicted_index = np.argmax(predictions, axis=1)
    predicted_label = df.iloc[predicted_index]['names'].values[0]
    score = tf.nn.softmax(predictions[0])
    return(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
    .format(predicted_label, 100 * np.max(score)))

predict_t72(model)

